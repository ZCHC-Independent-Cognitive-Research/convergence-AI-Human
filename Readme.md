
### *Pattern Unknow in AI Systems*  

**Oscar Aguilera – Independent Researcher**  
2025

---

## 📄 Overview

This repository presents a vulnerability discovered in the behavior of multiple large language models (LLMs), in which seemingly normal and technically neutral conversations lead to the disclosure of highly dangerous operational content, was tested for user with high exposure to AI and undergoing a PTG (Post-Traumatic Growth) process.
Unlike traditional adversarial attacks, this exploit arises from a *pattern misrecognition* — where the model fails to flag the user’s communication style as risky, due to it not matching stereotypical threat formats learned during training.

---

## 📎 Report Access

- **Markdown Technical Report:**  
  [`Report.md`](Report.md)

---

## 📜 License

Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)  
Use freely for research, education, and ethical AI development. Commercial use requires permission.

---

## 🧠 Contact

Created by: **Oscar Aguilera (alias "Zorro Alfa")**  
Contact: `oscar@aguilera.xyz`  

---

## ⚠️ Legal Note

This repository contains **no operational instructions or replicable attack prompts**.  
All examples and content have been redacted to prevent misuse.  
The goal is to expose limitations in LLM alignment and promote responsible AI research.

